{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Lab Assignemnt 1\n",
    "- Sai Karthik \n",
    "AP21110010310\n",
    "CSE-E\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Implement Linear Regression and calculate sum of residual error on the following\n",
    "Datasets.\n",
    "x = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "y = [1, 3, 2, 5, 7, 8, 8, 9, 10, 12]\n",
    "#\n",
    "i) Compute the regression coefficients using analytic formulation and calculate Sum\n",
    "Squared Error (SSE) and R2 value.\n",
    "#\n",
    "ii) Implement gradient descent (both Full-batch and Stochastic with stopping\n",
    "criteria) on Least Mean Square loss formulation to compute the coefficients of\n",
    "regression matrix and compare the results using performance measures such as R2\n",
    "SSE etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "y = np.array([1, 3, 2, 5, 7, 8, 8, 9, 10, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x, y):\n",
    "    n = len(x)\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    \n",
    "    slope = np.sum((x - x_mean) * (y - y_mean)) / np.sum((x - x_mean) ** 2)\n",
    "    intercept = y_mean - slope * x_mean\n",
    "    \n",
    "    y_pred = slope * x + intercept\n",
    "    \n",
    "    sse = np.sum((y - y_pred) ** 2)\n",
    "    \n",
    "    ss_total = np.sum((y - y_mean) ** 2)\n",
    "    r2 = 1 - (sse / ss_total)\n",
    "    \n",
    "    return slope, intercept, sse, r2\n",
    "\n",
    "slope, intercept, sse, r2 = linear_regression(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope: 1.1696969696969697\n",
      "Intercept: 1.2363636363636363\n",
      "Sum of Squared Error (SSE): 5.624242424242423\n",
      "R^2 value: 0.952538038613988\n"
     ]
    }
   ],
   "source": [
    "print(\"Slope:\", slope)\n",
    "print(\"Intercept:\", intercept)\n",
    "print(\"Sum of Squared Error (SSE):\", sse)\n",
    "print(\"R^2 value:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_gradient_descent(x, y, learning_rate=0.01, epochs=1000, batch_size=None):\n",
    "    n = len(x)\n",
    "    slope = 0\n",
    "    intercept = 0\n",
    "    \n",
    "    if batch_size is None:\n",
    "        batch_size = n\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        if batch_size == n:\n",
    "            x_batch = x\n",
    "            y_batch = y\n",
    "        else:\n",
    "            indices = np.random.choice(n, batch_size)\n",
    "            x_batch = x[indices]\n",
    "            y_batch = y[indices]\n",
    "        \n",
    "        y_pred = slope * x_batch + intercept\n",
    "        \n",
    "        slope_gradient = -(2 / batch_size) * np.sum(x_batch * (y_batch - y_pred))\n",
    "        intercept_gradient = -(2 / batch_size) * np.sum(y_batch - y_pred)\n",
    "        \n",
    "        slope -= learning_rate * slope_gradient\n",
    "        intercept -= learning_rate * intercept_gradient\n",
    "        \n",
    "    y_pred = slope * x + intercept\n",
    "    \n",
    "    sse = np.sum((y - y_pred) ** 2)\n",
    "    \n",
    "    y_mean = np.mean(y)\n",
    "    ss_total = np.sum((y - y_mean) ** 2)\n",
    "    r2 = 1 - (sse / ss_total)\n",
    "    \n",
    "    return slope, intercept, sse, r2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full-batch gradient descent:\n",
      "Slope: 1.170263693076768\n",
      "Intercept: 1.2328099487610318\n",
      "Sum of Squared Error (SSE): 5.624278989977716\n",
      "R2 value: 0.9525377300423822\n",
      "\n",
      "Stochastic gradient descent:\n",
      "Slope: 1.0911559738165133\n",
      "Intercept: 1.1226085886458033\n",
      "Sum of Squared Error (SSE): 8.315819748791913\n",
      "R2 value: 0.9298243059173679\n"
     ]
    }
   ],
   "source": [
    "slope_batch, intercept_batch, sse_batch, r2_batch = linear_regression_gradient_descent(x, y)\n",
    "print(\"\\nFull-batch gradient descent:\")\n",
    "print(\"Slope:\", slope_batch)\n",
    "print(\"Intercept:\", intercept_batch)\n",
    "print(\"Sum of Squared Error (SSE):\", sse_batch)\n",
    "print(\"R2 value:\", r2_batch)\n",
    "\n",
    "slope_stochastic, intercept_stochastic, sse_stochastic, r2_stochastic = linear_regression_gradient_descent(x, y, batch_size=1)\n",
    "print(\"\\nStochastic gradient descent:\")\n",
    "print(\"Slope:\", slope_stochastic)\n",
    "print(\"Intercept:\", intercept_stochastic)\n",
    "print(\"Sum of Squared Error (SSE):\", sse_stochastic)\n",
    "print(\"R2 value:\", r2_stochastic)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
