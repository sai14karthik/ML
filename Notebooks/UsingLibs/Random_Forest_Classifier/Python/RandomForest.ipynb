{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RandomForest.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1wTGyIWe8maiisGNznUk6JfRkQK6rCvaf","authorship_tag":"ABX9TyMzF7LgaJKuJTaZ2pG157p/"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"yp50EWDbAM8k","executionInfo":{"status":"ok","timestamp":1602445198726,"user_tz":-330,"elapsed":1333,"user":{"displayName":"Alakh Verma","photoUrl":"","userId":"12283462166930457910"}}},"source":["import os\n","from random import seed\n","from random import randrange #returns random numbers from a given range\n","from math import sqrt\n","from csv import reader #To read csv file without using read_csv of pandas"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"aUB90_9GAWh1","executionInfo":{"status":"ok","timestamp":1602445198729,"user_tz":-330,"elapsed":1313,"user":{"displayName":"Alakh Verma","photoUrl":"","userId":"12283462166930457910"}}},"source":["def load_csv(filename, header):\n","    # Initialize the dataset as list\n","    dset = list()\n","    \n","    # Open the dataset as readable file\n","    with open(filename, 'r') as file:\n","        \n","        #intialize the csv reader\n","        csv_reader = reader(file)\n","        \n","        #Append each row\n","        for row in csv_reader:\n","            \n","            if not row or not header:\n","                header = 1\n","                continue\n","            \n","            dset.append(row)\n","    \n","    return dset\n","\n","#Convert a string column(if present) to float\n","def str_col_to_float(dset, col):\n","    \n","    for row in dset:\n","        row[col] = float(row[col].strip())"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZNjyy41MAhqs","executionInfo":{"status":"ok","timestamp":1602445198731,"user_tz":-330,"elapsed":1301,"user":{"displayName":"Alakh Verma","photoUrl":"","userId":"12283462166930457910"}}},"source":["# Create dummy values for a string column. Convert the string to integer\n","def str_col_to_int(dset, col):\n","    \n","    #Store all the values of the column in a list\n","    class_values = [row[col] for row in dset]\n","    \n","    #Store the unique values\n","    uniq = set(class_values)\n","    \n","    #Create a dictionary with the lookup\n","    lookup = dict()\n","    for i, val in enumerate(uniq):\n","        lookup[val] = i\n","    \n","    #Now using the lookup change the string values to integer\n","    for row in dset:\n","        row[col] = lookup[row[col]]\n","    return lookup  \n","\n","# k-fold cross validation\n","def cross_validation_split(dset, k):\n","    \n","    fold_size = int(len(dset)/k) #Observations in each fold\n","    \n","    dset_cpy = list(dset) #Make a copy of the dataset\n","    \n","    dset_split = list() #Split dataset\n","    \n","    for i in range(k):\n","        \n","        fold = list()\n","        \n","        while len(fold) < fold_size:\n","            \n","            fold.append(dset_cpy.pop(randrange(len(dset_cpy))))\n","        \n","        dset_split.append(fold)\n","        \n","    return dset_split\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"EQhFgQO1ArHP","executionInfo":{"status":"ok","timestamp":1602445198733,"user_tz":-330,"elapsed":1290,"user":{"displayName":"Alakh Verma","photoUrl":"","userId":"12283462166930457910"}}},"source":["# Split the dataset into two based on a value\n","def test_split(col, val, dset):\n","    \n","    left, right = list(), list()\n","    \n","    for row in dset:\n","        \n","        if row[col] < val:\n","            \n","            left.append(row)\n","            \n","        else:\n","            \n","            right.append(row)\n","            \n","    return left, right\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"xFMItWn0AxDS","executionInfo":{"status":"ok","timestamp":1602445198734,"user_tz":-330,"elapsed":1277,"user":{"displayName":"Alakh Verma","photoUrl":"","userId":"12283462166930457910"}}},"source":["# Calculate accuracy percentage\n","def accuracy_metric(actual, predicted):\n","    \n","    correct = 0.0\n","    \n","    for i in range(len(actual)):\n","        \n","        if actual[i] == predicted[i]:\n","            correct += 1\n","    \n","    return correct/float(len(actual)) * 100.0\n","\n","#Evaluate function\n","def eval_algorithm(dset, algorithm, k, *args):\n","    \n","    folds = cross_validation_split(dset, k)\n","    scores = list()\n","    \n","    for fold in folds:\n","        \n","        #Create a copy of the data\n","        train_set = list(folds)\n","        \n","        #Remove the subsample\n","        train_set.remove(fold)\n","        \n","        #Create only one list\n","        train_set = sum(train_set, [])\n","        \n","        #Create test list\n","        test_set = list()\n","        for row in fold:\n","            \n","            row_cpy = list(row)\n","            test_set.append(row_cpy)\n","            row_cpy[-1] = None #Since the last column contains the dependent variable\n","            \n","        #Predicted values\n","        pred = algorithm(train_set, test_set, *args)\n","\n","        #Actual Values\n","        actual = [row[-1] for row in fold]\n","        \n","        #Accuracy\n","        accuracy = accuracy_metric(actual, pred)\n","        \n","        #Append to score list\n","        scores.append(accuracy)\n","        \n","    return scores\n"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nwk7r8eGA0CN","executionInfo":{"status":"ok","timestamp":1602445198736,"user_tz":-330,"elapsed":1270,"user":{"displayName":"Alakh Verma","photoUrl":"","userId":"12283462166930457910"}}},"source":["# Calculate Gini Index\n","def gini_index(groups, class_values):\n","    \n","    size0 = float(len(groups[0]))\n","    size1 = float(len(groups[1]))\n","    gini = 0\n","    \n","    for group in groups:\n","        \n","        if len(group) == 0:\n","            continue\n","            \n","        gini_group = 0\n","        \n","        for class_val in class_values:\n","            \n","            proportion = [row[-1] for row in group].count(class_val) / float(len(group))\n","            gini_group += (proportion*(1.0 - proportion))\n","            \n","#         gini += gini_group * len(group) / (size0 + size1)\n","        gini += gini_group \n","    \n","    return gini"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"YB_F3ukwA4DK","executionInfo":{"status":"ok","timestamp":1602445198737,"user_tz":-330,"elapsed":1263,"user":{"displayName":"Alakh Verma","photoUrl":"","userId":"12283462166930457910"}}},"source":["# Get split. To get the best feature - split threshold combination. This is a greedy algorithm\n","def get_split(dset, n_features):\n","    \n","    class_values = list(set([row[-1] for row in dset]))\n","    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n","    \n","    # Sample of all features for random forest\n","    feat_sub = list()\n","    while len(feat_sub) < n_features:\n","        \n","        index = randrange(len(dset[0]) - 1)\n","        \n","        if index in feat_sub:\n","#             feat_sub.append(index)\n","            continue\n","        \n","        feat_sub.append(index)\n","    \n","    for feature in feat_sub:\n","        \n","        for row in dset:\n","            \n","            groups = test_split(feature, row[feature], dset)\n","            gini = gini_index(groups, class_values)\n","            \n","            if gini < b_score:\n","                b_index, b_value, b_score, b_groups = feature, row[feature], gini, groups\n","    \n","    # Return a dictionary\n","    return {'index': b_index, 'value': b_value, 'groups': b_groups}"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"pYuVlBFtA-Ql","executionInfo":{"status":"ok","timestamp":1602445199144,"user_tz":-330,"elapsed":1663,"user":{"displayName":"Alakh Verma","photoUrl":"","userId":"12283462166930457910"}}},"source":["# Create terminal node value\n","def to_terminal(group):\n","    \n","    outcomes = [row[-1] for row in group]\n","    \n","    #returns the most common output value in a list of rows.\n","    return max(set(outcomes), key = outcomes.count)\n","\n","# Create the child nodes recursively\n","def split(node, max_depth, min_size, n_features, depth):\n","    \n","    # Store node in left and right\n","    left, right = node['groups']\n","    del(node['groups'])\n","    \n","    # If either of the group contains no value then we should stop and treat it as terminal node\n","    if not left or not right:\n","        node['left'] = node['right'] = to_terminal(left + right)\n","        return\n","    \n","    # If max depth is reached\n","    if depth >= max_depth:\n","        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n","        return\n","    \n","    # Left Node Split\n","    if len(left) <= min_size:\n","        node['left'] = to_terminal(left)\n","        \n","    else:\n","        node['left'] = get_split(left, n_features)\n","        split(node['left'], max_depth, min_size, n_features, depth+1)\n","        \n","    # Right Node Split\n","    if len(right) <= min_size:\n","        node['right'] = to_terminal(right)\n","        \n","    else:\n","        node['right'] = get_split(right, n_features)\n","        split(node['right'], max_depth, min_size, n_features, depth+1)\n","    \n","#Build a decision tree\n","def build_tree(train, max_depth, min_size, n_features):\n","    \n","    # Create the root node\n","    root = get_split(train, n_features)\n","    \n","    # Create child nodes\n","    split(root, max_depth, min_size, n_features, 1)\n","    \n","    return root\n"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"SnkRTAKGBC5o","executionInfo":{"status":"ok","timestamp":1602445199147,"user_tz":-330,"elapsed":1648,"user":{"displayName":"Alakh Verma","photoUrl":"","userId":"12283462166930457910"}}},"source":["# Prediction of a data point. The terminal nodes contain the modal class and other nodes are all dictionaries. So we \n","# need to find a way to navigate through the nodes according the given data point value and the values in each node. \n","# This could be done recursively as as we created the split\n","def predict(node, row):\n","    \n","    if row[node['index']] < node['value']:\n","        \n","        if isinstance(node['left'], dict):\n","            \n","            return predict(node['left'], row)\n","            \n","        else:\n","            \n","            return node['left']\n","        \n","    else:\n","        \n","        if isinstance(node['right'], dict):\n","            \n","            return predict(node['right'], row)\n","                \n","        else:\n","            \n","            return node['right']\n","    "],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"5EfXKbWmBEKq","executionInfo":{"status":"ok","timestamp":1602445199149,"user_tz":-330,"elapsed":1640,"user":{"displayName":"Alakh Verma","photoUrl":"","userId":"12283462166930457910"}}},"source":["# Create a random subsample from the dataset with replacement\n","def subsample(dset, ratio):\n","    \n","    n_samp = round(len(dset)*ratio)\n","    \n","    sample = list()\n","    \n","    while len(sample) < n_samp:\n","        \n","        index = randrange(len(dset))\n","        \n","        sample.append(dset[index])\n","    \n","    return sample"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"N1vHJQMQJ1UR","executionInfo":{"status":"ok","timestamp":1602445199150,"user_tz":-330,"elapsed":1632,"user":{"displayName":"Alakh Verma","photoUrl":"","userId":"12283462166930457910"}}},"source":["from sklearn import datasets"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"JgNAEPNxBLG9","executionInfo":{"status":"ok","timestamp":1602445200205,"user_tz":-330,"elapsed":2656,"user":{"displayName":"Alakh Verma","photoUrl":"","userId":"12283462166930457910"}}},"source":["dset = load_csv('/content/drive/My Drive/HR_Data.csv.txt', header = 0)\n","\n","# convert string attributes to integers\n","for i in range(0, len(dset[0])-1):\n","    str_col_to_float(dset, i)\n","\n","#Convert class column to integer\n","str_col_to_int(dset, len(dset[0])-1)\n","\n","# Bagging all the trees and produce predictions\n","def bagging_pred(trees, row):\n","    \n","    predictions = [predict(tree, row) for tree in trees]\n","    \n","    return max(set(predictions), key = predictions.count)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"WZY4HyF6Bb4q","executionInfo":{"status":"ok","timestamp":1602445213543,"user_tz":-330,"elapsed":15987,"user":{"displayName":"Alakh Verma","photoUrl":"","userId":"12283462166930457910"}},"outputId":"a3116858-e08b-4c06-8e91-6f3d6009b994","colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["# Random Forest Algorithm: Create multiple trees, subsample data and get scores\n","def random_forest(train_data, test_data, max_depth, min_size, sample_size, n_trees, n_features):\n","    \n","    trees = list()\n","    for i in range(n_trees):\n","            \n","            sample = subsample(train_data, sample_size)\n","            tree = build_tree(sample, max_depth, min_size, n_features)\n","            trees.append(tree)\n","    \n","    # Bag the results of all trees\n","    predictions = [bagging_pred(trees, row) for row in test_data]\n","    \n","    return(predictions)\n","\n","seed(1)\n","#Evaluation Algorithm\n","n_folds = 3 #k fold validation\n","max_depth = 10 #Maximum allowable depth of tree\n","min_size = 1 #Minimum size of in node\n","sample_size = 1.0 #Full or sample\n","n_features = int(sqrt(len(dset[0])-1)) #Number of features considered \n","n_trees = [1, 5] #Number of Trees for Random Forest\n","\n","for n_tree in n_trees:\n","    scores = eval_algorithm(dset, random_forest, n_folds, max_depth, min_size, sample_size, n_tree, n_features)\n","    print('Trees: %d' % n_tree)\n","    print('Scores: %s' % scores)\n","    print('Mean Accuracy: %.3f%%' % (sum(scores) / float(len(scores))))\n"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Trees: 1\n","Scores: [83.84458077709611, 84.04907975460122, 83.640081799591]\n","Mean Accuracy: 83.845%\n","Trees: 5\n","Scores: [83.640081799591, 85.2760736196319, 82.82208588957054]\n","Mean Accuracy: 83.913%\n"],"name":"stdout"}]}]}